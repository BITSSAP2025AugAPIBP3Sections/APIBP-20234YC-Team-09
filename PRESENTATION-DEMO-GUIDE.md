# üéØ ELK Stack + Selenium - Complete Demo Guide

## ‚úÖ Status Check

### Services Running:
- ‚úÖ Elasticsearch (Port 9200)
- ‚úÖ Logstash (Port 5044, 5000)
- ‚úÖ Kibana (Port 5601)
- ‚úÖ Filebeat
- ‚úÖ SonarQube (Port 9000)
- ‚ùå Your Application (Port 8000) - **NEED TO START**

---

## üöÄ Quick Demo Flow (Do This Now!)

### Step 1: Start Your Application
```bash
# Open a new terminal and run:
cd backend
npm start
```
**Wait for**: "Server ready on port 8000"

### Step 2: Access Kibana (3-5 minutes after starting)
Open browser: **http://localhost:5601**

- First time will take 2-3 minutes to fully load
- You'll see Kibana home screen

### Step 3: Create Index Pattern in Kibana
1. Click **‚ò∞ Menu** (top left) ‚Üí **Management** ‚Üí **Stack Management**
2. Under "Kibana", click **Index Patterns**
3. Click **Create index pattern** button
4. Enter: `fusion-logs-*`
5. Click **Next step**
6. Select **@timestamp** as time field
7. Click **Create index pattern**

### Step 4: Generate Traffic & Logs
```bash
# In a new terminal:
node generate-test-logs.js
```

### Step 5: View Logs in Kibana
1. Click **‚ò∞ Menu** ‚Üí **Discover**
2. Select `fusion-logs-*` index pattern (top left)
3. You'll see all logs with:
   - ‚úÖ Timestamp
   - ‚úÖ Log level (info, warn, error)
   - ‚úÖ HTTP method
   - ‚úÖ API path
   - ‚úÖ Response time
   - ‚úÖ Status codes

---

## üì∏ Screenshot Checklist for Presentation

### 1. Docker Services Running
```bash
docker ps --format "table {{.Names}}\t{{.Status}}\t{{.Ports}}"
```
**Screenshot**: All ELK containers + SonarQube running

### 2. Kibana Dashboard
**URL**: http://localhost:5601
**Screenshot**: Kibana home screen

### 3. Logs Flowing in Real-Time
**Screenshot**: Discover tab showing live logs

### 4. Filter Errors
In Kibana search bar, type: `level: error`
**Screenshot**: Filtered error logs

### 5. Response Time Metrics
Create visualization showing average response time
**Screenshot**: Response time chart

### 6. API Request Distribution
Create pie chart of status codes
**Screenshot**: Status code distribution

---

## üé§ Presentation Script

### Introduction (30 seconds)
"For centralized logging and monitoring, I've integrated the ELK Stack - Elasticsearch, Logstash, and Kibana."

### Architecture (1 minute)
"The architecture works like this:
1. Our Node.js application writes logs to files
2. Filebeat collects these logs
3. Logstash processes and enriches them
4. Elasticsearch stores and indexes them
5. Kibana provides visualization and querying"

[Show docker-compose-elk.yml]

### Live Demo (2 minutes)

**Show Docker containers:**
```bash
docker ps | findstr fusion
```

**Show Kibana:**
- Open http://localhost:5601
- Navigate to Discover
- Show real-time logs

**Generate traffic:**
```bash
node generate-test-logs.js
```

**Show logs appearing:**
- Refresh Kibana
- Point out the new requests
- Show different log levels
- Show response times

**Filter for errors:**
- Type: `level: error`
- Show error details

### Benefits (30 seconds)
"This gives us:
- ‚úÖ Centralized logging from all services
- ‚úÖ Real-time monitoring
- ‚úÖ Error tracking and alerting
- ‚úÖ Performance analysis
- ‚úÖ Production debugging capabilities"

---

## üî• Quick Demos You Can Run

### Demo 1: Real-Time Logging
```bash
# Terminal 1: Watch logs
docker logs -f fusion-logstash

# Terminal 2: Generate requests
curl http://localhost:8000/api/products
curl http://localhost:8000/api/search?q=laptop
```

### Demo 2: Error Tracking
```bash
# Generate an error
curl http://localhost:8000/api/nonexistent

# Show in Kibana: level: error
```

### Demo 3: Performance Monitoring
```bash
# Make 10 requests
for ($i=1; $i -le 10; $i++) { curl http://localhost:8000/api/products }

# Show response time distribution in Kibana
```

---

## üé® Kibana Visualizations to Create (Optional - If Time)

### 1. Request Rate Over Time
- **Type**: Area chart
- **Y-axis**: Count
- **X-axis**: @timestamp (Date Histogram)

### 2. Average Response Time
- **Type**: Metric
- **Aggregation**: Average of `duration`

### 3. Status Code Breakdown
- **Type**: Pie chart
- **Slice by**: `statusCode`

### 4. Top API Endpoints
- **Type**: Bar chart
- **Y-axis**: Count
- **X-axis**: `path.keyword` (Terms, Top 10)

### 5. Error Log Table
- **Type**: Data table
- **Filter**: `level: error`
- **Columns**: timestamp, message, path, statusCode

---

## üÜö AWS Deployment Option

### Yes, use your AWS credits! Here's how:

#### Option 1: Amazon Elasticsearch Service (Managed)
**Pros:**
- ‚úÖ Fully managed
- ‚úÖ Auto-scaling
- ‚úÖ Built-in security
- ‚úÖ No server management

**Cons:**
- ‚ùå More expensive (~$50-100/month)
- ‚ùå Less control

**Setup:**
1. AWS Console ‚Üí Elasticsearch Service
2. Create domain
3. Choose t3.small.elasticsearch (free tier eligible)
4. Enable Kibana authentication
5. Update application to send logs to AWS endpoint

#### Option 2: EC2 with Docker (What I Recommend)
**Pros:**
- ‚úÖ Full control
- ‚úÖ Cheaper (~$30-50/month)
- ‚úÖ Same setup as local
- ‚úÖ Easy to demo

**Cons:**
- ‚ùå You manage everything

**Quick Setup:**
```bash
# 1. Launch EC2 instance
# - Instance type: t3.large (2 vCPU, 8 GB RAM)
# - AMI: Ubuntu 22.04
# - Security group: Open ports 9200, 5601, 5044, 8000

# 2. SSH to instance
ssh -i your-key.pem ubuntu@your-ec2-ip

# 3. Install Docker
curl -fsSL https://get.docker.com -o get-docker.sh
sudo sh get-docker.sh
sudo usermod -aG docker ubuntu

# 4. Clone your repo
git clone https://github.com/your-repo.git
cd MERN-Stack-Ecommerce-App

# 5. Start ELK Stack
docker-compose -f docker-compose-elk.yml up -d

# 6. Start your application
cd backend
npm install
npm start
```

#### Cost Estimation:
- **t3.large EC2**: ~$0.08/hour = ~$60/month
- **Storage (50 GB EBS)**: ~$5/month
- **Data transfer**: Minimal for demo
- **Total**: ~$65/month (easily fits in $100 credit)

---

## üí° Pro Tips for Presentation

1. **Start ELK 10 minutes before presentation**
   - Services need 3-5 minutes to initialize
   - Index patterns need time to populate

2. **Have screenshots ready as backup**
   - In case services are slow
   - Network issues

3. **Prepare sample queries**
   - Write them down beforehand
   - Don't type live during demo

4. **Know your numbers**
   - "Processing X requests per second"
   - "Average response time: Y ms"
   - "Total logs indexed: Z"

5. **Show progression**
   - Start with simple: "Here are logs"
   - Move to advanced: "Now let's filter errors"
   - Finish with impact: "This helps us debug production issues"

---

## üêõ Troubleshooting

### Kibana not loading?
```bash
# Check Elasticsearch health
curl http://localhost:9200/_cluster/health

# Restart Kibana
docker restart fusion-kibana

# Wait 2-3 minutes
```

### No logs appearing?
```bash
# Check if application is running
curl http://localhost:8000/api/products

# Check log file exists
dir logs

# Check Logstash is processing
docker logs fusion-logstash | Select-String -Pattern "Pipeline started"
```

### Elasticsearch yellow status?
**Normal for single-node setup!** It's just a warning about no replicas.

---

## ‚ö° Final Checklist Before Demo

- [ ] All Docker containers running (`docker ps`)
- [ ] Application running on port 8000
- [ ] Kibana accessible at localhost:5601
- [ ] Index pattern `fusion-logs-*` created
- [ ] Test logs generated and visible
- [ ] Screenshots captured
- [ ] AWS account ready (if deploying)
- [ ] Backup plan (screenshots) ready

---

## üéì Talking Points

**Why ELK?**
- "Industry standard for log management"
- "Used by Netflix, Uber, LinkedIn"
- "Essential for microservices architecture"

**Real-world use cases:**
- "Debug production issues without SSH access"
- "Monitor API performance in real-time"
- "Set up alerts for critical errors"
- "Track user behavior patterns"

**DevOps integration:**
- "Logs from all services in one place"
- "Integrates with CI/CD pipelines"
- "Can trigger alerts to PagerDuty/Slack"
- "Historical data for trend analysis"

---

**Ready to Demo!** üöÄ

Run: `docker ps` and `npm start` and you're good to go!
